---
title: "Supplementary Information"
author: "Shawn Cummings and T. Florian Jaeger"
date: "\today"
output:
  word_document:
    toc: yes
    toc_depth: '4'
  fontsize: 10pt
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '4'
  pdf_document:
    fig_caption: yes
    fig_width: 7
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 4
geometry: margin=2cm
header-includes:
- \usepackage{booktabs}
- \usepackage{siunitx}
- \usepackage{tabto}
- \usepackage{soul}
- \usepackage{xcolor}
- \usepackage{placeins}
- \usepackage{lscape}
- \usepackage{animate}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
- \makeatletter\renewcommand{\fps@table}{!ht}\makeatother
- \setstcolor{red}
- \usepackage{sectsty}
- \sectionfont{\color{blue}}
- \subsectionfont{\color{blue}}
- \subsubsectionfont{\color{darkgray}}
---

```{r, include=FALSE}
library(tidyverse)
library(magrittr)    # pipes
library(lubridate)   # date conversion, etc.

library(brms)        # Bayesian GL(M)Ms
library(tidybayes)   # extract posterior from brmfits
library(modelr)      # create data grids
library(sjPlot)      # tables for Bayesian GL(M)Ms
library(broom)       # extracting information from GL(M)Ms
library(boot)        # easy logit() function

library(knitr)
library(linguisticsdown)  #IPA symbols
library(rstan)

# Setting up cmdstanr
# library(curl)
# if (has_internet()) install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library(cmdstanr)
# install_cmdstan()
```

```{r constants, include=FALSE}
source("constants.R")
```

```{r, include=FALSE}
opts_chunk$set(dev = 'png', dpi = 96,
               comment="", 
               echo=FALSE, warning=TRUE, message=TRUE,
               cache=FALSE, 
               size="small",
               tidy.opts = list(width.cutoff = 200),
               fig.width = fig.base_width, fig.height = fig.base_height, fig.align = "center")

def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

color_block = function(color) {
  function(x, options) sprintf('\\color{%s}\\begin{verbatim}%s\\end{verbatim}\\color{black}',
                               color, x)
}
knitr::knit_hooks$set(error = color_block('red'))
knitr::knit_hooks$set(warning = color_block('orange'))
```

```{r functions to consolidate}
format_more <- 
  . %>%
  # Potentially move these into the format function
  rename_with(~ gsub("Answer.", "", .x)) %>%
  rename(
    Participant.AudioType = audio_type,
    Participant.AudioStall = audio_stall,
    Participant.VideoStall = video_stall,
    Talker.Sex = sex,
    Talker.PronunciationShift = ssh2,
    Talker.PronunciationProperties = pronun,
    Talker.SpeechDescription = speaker) %>%
  add_exclusions() %>%
  mutate(
    Condition.Exposure.Pen = NA,
    Condition.Exposure.LexicalLabel = NA,
    Response.ASHI = ifelse(Response == "ASHI", 1, 0)) %>%
  select(
    Experiment, ParticipantID, starts_with("Participant."),
    Condition.Exposure.Pen, Condition.Exposure.LexicalLabel, 
    Condition.Test.Audio, Condition.Test.Pen, Condition.Test.OriginalLabel, Condition.Test.Keybindings,
    Phase, Block, Trial, ItemID, 
    Response, Response.ASHI, Response.RT, Response.CatchTrial,
    starts_with("Talker"),
    starts_with("Duration"),
    starts_with("Exclude")) 
```

# Context statement
This document contains the data preparation, visualization, and analyses reported in the main text. As of 2022, the Human Language Processing Lab, University of Rochester, is committed to producing articles and supplementary information in the form of R Markdown documents whenever possible. This particular project grew out of a yearlong undergraduate research class (BCS 206/7 "Undergraduate Research in Cognitive Science"). To accommodate differences in familiarity with R programming, and to facilitate project workflow, the authors agreed to write the main text in a common word processing software, and to provide this R Markdown document as supplementary information.

# Chronology of Experiments (NEEDS WORK)
We conducted five test-only and six exposure-test experiments for this project. The main text does summarize these experiments in the order that makes them most accessible. Here we summarize when those experiments were conducted. 
<!-- TO DO: fill in missing dates and subject N XXX--->

 * **Experiment 1a:** test-only experiment (N = 64) conducted over MTurk between 01/20-22/2021. 
 * **Experiment 1b:** test-only experiment (N = 64) conducted over MTurk between 03/03-04/2021. 
 * **Experiment XXX:** exposure-test experiment (N = XXX) conducted over MTurk between 03/XXX-XXX/2021. 
 * **Experiment 1c:** test-only experiment (N = 64) conducted over MTurk between 06/03-05/2021. 
 * **Experiment 2:** test-only experiment (N = 64) conducted over MTurk between  07/14-15/2021. 
 * **Experiment 2b:** test-only experiment (N = 64) conducted over MTurk between 07/23-24/2021.
 * **Experiment XXX:** exposure-test experiment (N = XXX) conducted over MTurk between 08/XXX-XXX/2021. 
 * **Experiment XXX:** practice-only pilot (N = 32) conducted over MTurk between 11/XXX-XXX/2021. 
 * **Experiment XXX:** practice-only pilot (N = 22) conducted over MTurk between 12/XXX-XXX/2021. 
 * **Experiment 3:** exposure-test experiment (N = 257) conducted over Prolific between 05/XXX-XXX/2022. 
 * **Experiment 4:** exposure-test experiment (N = XXX) conducted over Prolific between 07/XXX-XXX/2022. 
 

 * Experiment-A:
   *  2x2x2 design: 2 pen location in exposure (hand or mouth) x 2 bias (S or SH) x 2 pen location in test (hand or mouth, manipulated within-subject)
   * Used the same audio steps as what we're now calling Exp 1b (10, 13, 14, 15, 16, 20 ASHI-high, resulting in too many S responses across the board)
   * In PIM condition, pen was also in mouth during *typical* trials (unlike in Kraljic and Liu experiments)

 * Experiment-B:
   * Replication intended to fix audio step mishap
   * Identical design as Experiment-A
   * Corrected the audio steps, and used the same as what we're now calling Exp 1c (13, 18, 19, 20, 21, 26 ASHI-high)
   * In PIM condition, pen was also in mouth during *typical* trials (unlike in Kraljic and Liu experiments)

<!-- TO DO: correct? -->

 * Experiment-C, Experiment-D:
   * Norms toying with the practice setup

 * Experiment-Prolific-E (May 2022): ------- Experiment 3?
    * The good one: Replication with lessons learned
    * Same 2x2x2 as Experiments A & B
    * Included new 6-trial practice phase, but did not restart if people missed trials (enforcePerfection = F)
    * Used correct audio steps (Experiment 1c)

 * Experiment-2A/Prolific-F (July 2022): ----- Experiment 4
   * Final manipulation to disambiguate causality of shift
   * New exposure setup: all subjects get two blocks of exposure, the first shifted with pen in mouth and the second typical with pen in hand.
   * 2 x 2 of bias (S or SH, between subjects), and pen location in test (hand or mouth, within-subject)
   * Did not include e.g. a condition where the talker's speech is still shifted when she removes the pen from her mouth, or where the speech is typical with pen in mouth but then becomes shifted when the pen leaves the mouth. 


# Experiments 1a-c

## Data import

```{r}
load("../data/Experiment-NORM-A-before-exclusions.RData") 
d.Exp1a <- 
  d.test.A %>%
  mutate(
    Experiment = "CISP-1a",
    ParticipantID = paste(Experiment, ParticipantID, sep = "."))
 
load("../data/Experiment-NORM-B-before-exclusions.RData") 
d.Exp1b <- 
  d.test.B %>%
  mutate(
    Experiment = "CISP-1b",
    ParticipantID = paste(Experiment, ParticipantID, sep = "."))

load("../data/Experiment-NORM-C-before-exclusions.RData") 
d.Exp1c <- 
  d.test.C %>%
  mutate(
    Experiment = "CISP-1c",
    ParticipantID = paste(Experiment, ParticipantID, sep = "."))

d.LJ18.test <- 
  read.csv("../data/Liu Jaeger 2018/Liu-Jaeger-2018-test-1-s2.0-S0010027718300118-mmc2.csv") %>%
  # Filter to norming experiment
  filter(
    Condition == 'Filler') %>%
  mutate(
    Experiment = factor('LJ18-NORM'),
    ParticipantID = as.factor(paste0("LJ18.", Subject)), 
    Condition.Test.Audio = Step, 
    Condition.Test.Pen = "audio-only",
    Condition.Test.OriginalLabel = NA,
    Response = factor(case_when(Response == "SH" ~ "ASHI", Response == "S" ~ "ASI")),
    # Blocks were 6 trials per block in LJ18 but 12 in CISP, so we re-calculate
    # blocks for LJ18 to be blocks of 12 trials.
    Block = Trial %/% 12 + 1, 
    Trial = Trial + 1,
    across(c(Condition.Test.Pen, Condition.Test.OriginalLabel), factor))

d.test <- 
  bind_rows(d.Exp1a, d.Exp1b, d.Exp1c, d.LJ18.test) %>%
  format_more()

rm(d.test.A, d.test.B, d.test.C)
```

## Materials: Selection of acoustic continuum steps
As described in the main text, we aimed to maximize the power to detect effects---like that oc the pen in the mouth---along the *asi-ashi* continuum. Specifically, we aimed to select one step that, across all other manipulations, would yield approximated 25% *ashi* responses, four steps that would yield close to 50% *ashi* responses, and one step that would yield 75% *ashi* responses.

The intention for Experiment 1a was to employ the exact same acoustic steps as in @liu-jaeger2018: 12, 14, 15, 16, 17, and 19, where higher numbers indicate acoustically more ashi-like steps. However, a labelling mistake resulted in the steps being internally named with higher numbers indicating proportion of asi, rather than ashi. The actual steps that were used in Experiment 1a were 13, 15, 16, 17, 18, 20 unintentionally shifting the test continuum 1 step towards the ashi end, compared to @liu-jaeger2018. As we report below, Experiment 1a yielded overall more asi than ashi responses. Experiment 1b thus attempted to expand the test stimuli towards the ashi end of the continuum. However, as we still had not discovered the labeling mistake, we ended up expanding the continuum even further towards the asi end instead, with steps 10, 13, 14, 15, 16, 20. At this point, we identified the labeling mistake. Experiment 1c employed steps 13, 17, 18, 19, 20, and 24. We emphasize that the location of the test steps is not critical for Experiments 1a-c.

## Procedure: Further details on exit survey
<!-- TO DO SHAWN: could you fill in more information about the questions we asked, including a full list of questions? -->

For Experiment 1b, we made minor changes to the survey. We removed one question about audio quality which asked participants to rate the quality of their audio equipment as "bad", "good", "professional", etc. Previous analyses in our lab have found that the subjective nature of this question makes it hard to interpret. And, in order to encourage the participants to answer survey questions truthfully, we emphasized that they would get compensated independent of their answers, and that truthful answers would greatly help us with the interpretation of results. <!-- TO DO: please check whether this is all correct. I believe we have detailed notes about these changes both in an RMD file I created back then, and in the Javascript / survey code itself. -->

For Experiment 1c, we revised our questions about internet connectivity. Specifically, we changed the two questions that asked about video or sound issues during the experiment. We clarified that these questions were asking solely about technical issues, rather than any oddities between the alignment of the video and audio (as separate questions already assessed that aspect). The revised questions were introduced by the following statement: "The videos and sounds in this experiment were manipulated by aligning the same video with different sound sources. As a consequence, you might have noticed some 'jumps' or slightly odd-looking moments in the video. Here we are interested in *potential technical issues with the internet connection* beyond any oddities you might have noticed about how the video and sound aligned." (emphasis in original) Then two questions assessed whether the videos or sounds failed to load or stopped and restarted playing during exposure. As these revised questions explicitly mentioned that the videos and sounds had been manipulated, they were moved towards the end of the survey, so that they followed any questions that inquired about the pronunciation of the talker in the video (recall that participants could not go back to previously answered questions). <!-- TO DO: please check whether this is all correct. I believe we have detailed notes about these changes both in an RMD file I created back then, and in the Javascript / survey code itself. -->

## Exclusions

```{r exclusions, fig.width=4*fig.base_width, fig.height=fig.base_height }
d.test.Exp1 <-
  d.test %>% 
  run_exclusions(c("CISP-1a", "CISP-1b", "CISP-1c"))

d.test %<>%
  excludeData() %>%
  filter(!is.na(Response.ASHI))
```

## Analyses

```{r}
p <- plot_data(d.test, experiment = c("CISP-1a", "CISP-1b", "CISP-1c"), background_experiment = "LJ18-NORM")
plot(p)
  
ggsave(
  p,
  file = "../figures/Experiment 1a-c.png", 
  width = fig.base_width * 3,
  height = fig.base_height * 3 + .25)
```


### Experiment 1a

```{r results='markup'}
m.Exp1a <- fit_test_model(d.test.Exp1, "CISP-1a")
my_hypotheses(m.Exp1a, experiment = "Exp 1a") %>% map(print) -> TEMP

# Sanity check to see whether there are other significant effects, not included in hypothesis tests
summary(m.Exp1a)$fixed %>% filter(map2(`l-95% CI`, `u-95% CI`, ~ !between(0, .x, .y)) %>% unlist())
plot_model_predictions(m.Exp1a)
```


### Experiment 1b

```{r}
m.Exp1b <- fit_test_model(d.test.Exp1, "CISP-1b")
my_hypotheses(m.Exp1b, experiment = "Exp 1b") %>% map(print) -> TEMP
# Sanity check to see whether there are other significant effects, not included in hypothesis tests
summary(m.Exp1b)$fixed %>% filter(map2(`l-95% CI`, `u-95% CI`, ~ !between(0, .x, .y)) %>% unlist())

plot_model_predictions(m.Exp1b)
```

### Experiment 1c

```{r}
m.Exp1c <- fit_test_model(d.test.Exp1, "CISP-1c")
my_hypotheses(m.Exp1c, experiment = "Exp 1c")  %>% map(print) -> TEMP
# Sanity check to see whether there are other significant effects, not included in hypothesis tests
summary(m.Exp1c)$fixed %>% filter(map2(`l-95% CI`, `u-95% CI`, ~ !between(0, .x, .y)) %>% unlist())

plot_model_predictions(m.Exp1c)
```
### Liu and Jaeger (2018)
For comparison, we also analyzed the "baseline" experiment from Liu and Jaeger (2018, Experiment 1a-b) with the same analysis approach employed in the present study. Like all previous work in this line of research, this baseline experiment employed audio-only test stimuli. Unlike our Experiments 1a-c, Liu and Jaeger's control experiment contained an exposure phase (with only typical fricative pronunications). We further note that none of Experiments 1a-c employed the exact same continuum steps as Liu and Jaeger (2018). It is known that the selection of acoustic continuum steps that participants experience in an experiment can affect their categorization responses: even the exact same continuum step can be categorized differently depending on the other steps included in the experiment (Yamata & Tohkura, 1992). These factors limit the extent to which our Experiments 1a-c can be directly compared to Liu and Jaeger's audio-only experiment. We thus focus only on the magnitude of the acoustic effects in Liu and Jaeger, compared to the present experiments.

```{r}
d.test.LJ18 <- 
  d.test %>%
  run_exclusions("LJ18-NORM")

m.LJ18 <- fit_test_model(d.test.LJ18, "LJ18-NORM")
my_LJ18_hypothesis <- function(m, experiment = "LJ18-NORM") {
  format <-  
    . %>%
    rename(BF = Evid.Ratio) %>%
    mutate(
      Experiment = experiment,
      across(
        c("Estimate", "Est.Error", starts_with("CI"), "Post.Prob"),
        ~ signif(.x, 3)),
      BF = ifelse(is.infinite(BF), paste(">", ndraws(m)), as.character(round(BF, 1)))) %>% 
    relocate(Experiment, everything())
  
  hypothesis(
    m, 
    c("bsp_moCondition.Test.Audio > 0",
      "bsp_moBlock:moCondition.Test.Audio = 0"), 
    class = NULL, scope = "standard") %>%
    .[["hypothesis"]] %>% 
    mutate(
      Experiment = "LJ18-NORM",
      Hypothesis = c(
        "Acoustic continuum more ASHI-like -> more ASHI-responses",
        "Continuum effect is stable over blocks")) %>% 
    format() %>%
    kable(caption = "Effects of acoustic continuum.")
}

my_LJ18_hypothesis(m.LJ18)
# Sanity check to see whether there are other significant effects, not included in hypothesis tests
summary(m.LJ18)$fixed %>% filter(map2(`l-95% CI`, `u-95% CI`, ~ !between(0, .x, .y)) %>% unlist())

plot_model_predictions(m.LJ18)

d.test.LJ18 %>% 
  data_grid(ParticipantID, Condition.Test.Audio, Block = 1) %>%
  add_epred_draws(m.LJ18, re_formula = NULL) %>%
  ggplot(aes(x = Condition.Test.Audio, y = Response.ASHI)) +
  stat_lineribbon(aes(y = .epred), color = "black") +
  stat_summary(
    data = 
      d.test.LJ18 %>% 
      filter(Block == 1) %>%
      group_by(ParticipantID, Condition.Test.Audio) %>%
      summarise(Response.ASHI = mean(Response.ASHI)),
    geom = "pointrange",
    color = "black") +
  scale_fill_grey()
```

# Experiments 2 and 2b
We conducted two experiments that were designed to test whether listeners need to see the effects of the pen on the articulators *during the production of the fricative*, or whether the presence of a pen during the production of a fricative is sufficient to cause the effects observed in Experiments 1a-c. To this end, Experiments 2 and 2b introduced a black box that occluded the talker's mouth during the articulation of the fricative (see main text for details). The two experiments were identical except that Experiment 2b introduced an additional task intended to assure that participants paid attention to the videos (rather than just the audio). This change in procedure from Experiment 2 to 2b was intended to address an alternative explanation for the results of Experiment 2. As reported below, Experiment 2 did not find the effects of pen location that were present in Experiments 1a-c. This raised the question as to whether participants in Experiment 2 failed to pay attention to the video (unlike in Experiments 1a-c). The additional task in Experiment 2b addressed this possibility.

## Data import

```{r}
load("../data/Experiment-NORM-D-before-exclusions.RData") #named d.test.D
load("../data/Experiment-NORM-E-before-exclusions.RData") #named d.test.E

d.Exp2 <- 
  d.test.D %>%
  mutate(
    Experiment = "CISP-2",
    ParticipantID = paste(Experiment, ParticipantID, sep = "."))
 
d.Exp2b <- 
  d.test.E %>%
  mutate(Participant.Age = as.double(Participant.Age)) %>%
  mutate(
    Experiment = "CISP-2b",
    ParticipantID = paste(Experiment, ParticipantID, sep = "."))

d.test.Exp2 <- 
  bind_rows(d.Exp2, d.Exp2b) %>%
  format_more()

rm(d.test.D, d.test.E)
```

## Procedure
Experiment 2 employed the exact same tasks as Experiment 1a-c. Experiment 2b, however, introduced an additional task. Participants were asked to press SPACE whenever the pen was in the talker's mouth. After pressing SPACE, participants had to answer whether they heard *asi* or *ashi*, as in all preceding experiments. Figure \@ref(fig:XXX) shows a screenshot of the specific instructions. 

<!-- TO DO: Shawn, can we add the screen shot from your email here, or perhaps a screen shot of the entire screen, incl. the part you had in your email -->

## Exclusions
Figure \@ref(fig:XXX) summarized the exclusions for Experiment 2 and 2b. Of note is the high exclusion rate for Experiment 2b, for which almost one fourth of all participants stated after the experiment that they had not been wearing head phones. This deterioration of data quality for experiments conducted over Mechanical Turk post 2020 was also observed in other experiments conducted in our lab during the same time period. Like in the present case, deterioration of data quality tended to be particularly pronounced in those other studies when we conducted a series of experiments, One possible explanation is our recruitment criterion, which only allowed participants to see the experiment if they had *not* participated in any previous experiment of the series. This successively reduces the participant pool, potentially making the experiment vulnerable to increasingly less cooperative participants. 

This motivated our switch to the Prolific crowdsourcing experiments for subsequent experiments. Experiment 2b was the last experiment we conducted over Mechanical Turk. <!-- TO DO: correct? -->

```{r}
d.test.Exp2 %<>% run_exclusions(c("CISP-2", "CISP-2b"))
```

### Experiment 2

```{r}
p <- 
  plot_data(
    bind_rows(d.test.Exp1, d.test.Exp2), 
    experiment = "CISP-2", background_experiment = "CISP-1c")
plot(p)

ggsave(
  p,
  file = "../figures/Experiment 2.png", 
  width = fig.base_width * 3,
  height = fig.base_height + .5)
```

```{r results='markup'}
m.Exp2 <- fit_test_model(d.test.Exp2, experiment = "CISP-2")
my_hypotheses(m.Exp2, experiment = "Exp 2") %>% map(print) -> TEMP
plot_model_predictions(m.Exp2)
```

### Comparison of Experiment 2a against Experiment 1c

```{r results='markup'}
m.Exp2vsExp1c <- fit_test_model(data = bind_rows(d.test.Exp1, d.test.Exp2), experiment = c("CISP-1c", "CISP-2"))
# bind_rows(d.test.Exp1, d.test.Exp2) %>% filter(Experiment %in% c("CISP-1c", "CISP-2")) %>% prep_for_analysis() %>% pull(Experiment)

# Experiment 2 is coded as 1 vs. Experiment 1c coded as -1
# Does Experiment 2 have more ASHI responses (in the middle of the continuum), as would be expected if pen location
# was not due to occlusion (since pen-in-mouth reduced ASHI responses)? YES, somewhat
hypothesis(m.Exp2vsExp1c, "b_Experiment1 + 2.5 * bsp_moCondition.Test.Audio:Experiment1 > 0", class = NULL)
# Is there still an affect of pen across the two experiments? YES, kinda.
hypothesis(m.Exp2vsExp1c, "b_Condition.Test.PenM  + 2.5 * bsp_moCondition.Test.Audio:Condition.Test.PenM < 0", class = NULL)
# And, is that effect of pen reduced (less negative) in Experiment 2 than in Experiment 1c? NOT REALLY?!?!
hypothesis(m.Exp2vsExp1c, "b_Condition.Test.PenM:Experiment1 > 0", class = NULL)
hypothesis(m.Exp2vsExp1c, "bsp_moCondition.Test.Audio:Experiment1 > 0", class = NULL)
hypothesis(m.Exp2vsExp1c, "bsp_moCondition.Test.Audio:Condition.Test.PenM < 0", class = NULL)
hypothesis(m.Exp2vsExp1c, "bsp_moCondition.Test.Audio:Condition.Test.PenM:Experiment1 > 0", class = NULL)

summary(m.Exp2vsExp1c)$fixed %>% filter(map2(`l-95% CI`, `u-95% CI`, ~ !between(0, .x, .y)) %>% unlist())
conditional_effects(m.Exp2vsExp1c, 
                    effects = "Condition.Test.Audio:Condition.Test.Pen",
                    conditions = tibble(Experiment = c("CISP-1c", "CISP-2"),
                                        Block = 5), 
                    robust = T, 
                    method = "posterior_linpred")
summary(m.Exp2vsExp1c)$fixed
```

### Experiment 2b
We first analyzed the accuracy of SPACE presses. Participants were significantly above chance in detecting the pen in the mouth of the talker (75% accurate). Participants were, however, much more accurate when the pen was not in the mouth of the talker (95%). This asymmetry is not particularly surprising: correct detection of the pen in the mouth required a key press, whereas correct detection that the pen was not in the mouth (but rather in the hand) required no action at all.

```{r}
d.test.Exp2 %>%
  mutate(Reponse.CatchCorrect = ifelse(Response.CatchTrial == (Condition.Test.Pen == "mouth"), 1, 0)) %>%
  ggplot(aes(x = Condition.Test.Pen, y = Reponse.CatchCorrect, shape = Condition.Test.Pen)) +
  stat_summary(fun.data = mean_cl_boot, geom = "pointrange") +
  scale_x_discrete(
    "Pen location", 
    breaks = levels.test.pen_locations, 
    labels = labels.test.pen_locations) +
  scale_y_continuous("Proportion correct responses about pen location") +
  scale_shape_manual(
    "Pen location", 
    breaks = levels.test.pen_locations, labels = labels.test.pen_locations, values = shapes.test.pen_locations)
```

Next, we turn to participants categorization responses---i.e., whether participants heard *asi* or *ashi*. Figure \@ref(fig:results-exp2b) summarizes participants' categorization responses. Compared to Experiment 2, participants in Experiment 2b exhibited noticeably weaker effects of the acoustic continuum (more shallow slope in Figure \@ref(fig:results-exp2b)a). This suggests a trade-off introduced by the secondary task in Experiment 2b: either because participants focused more on the visual input, or because the categorization response was delivered *after* the response to the visual stimulus (SPACE press), participants' responses were less affected by the acoustic continuum. Critically, however, Experiment 2b replicates all effects found in Experiment 2. 

(ref:results-exp2b) Summary of participants’ responses in Experiments 2b, depending on pen location and acoustic continuum step (Panel A) or visual bias (Panel B). For comparison, the results from Experiment 2 are shown in the background. The two experiments were identical except for the secondary task introduced in Experiment 2b.

```{r results-exp2b, fig.width=fig.base_width * 3, fig.height=fig.base_height + .5, fig.cap="(ref:results-exp2b)"}
p <-
  plot_data(
    bind_rows(d.test.Exp1, d.test.Exp2), 
    experiment = "CISP-2b", background_experiment = "CISP-2")
plot(p)

ggsave(
  p,
  file = "../figures/Experiment 2b.png", 
  width = fig.base_width * 3,
  height = fig.base_height + .5)
```

```{r}
m.Exp2b <- fit_test_model(d.test.Exp2, "CISP-2b")
my_hypotheses(m.Exp2b, experiment = "Exp 2b") %>% map(print) -> TEMP
plot_model_predictions(m.Exp2b)
```

# Experiment 3
Experiment 3 was conducted XXX

## Data import

```{r}
rm(d.Exp2)
load("../data/Experiment-3-before-exclusions.RData") 
d.Exp3 <- 
  d.Exp2 %>%
  mutate(
    Experiment = "CISP-3",
    Condition.Test.Keybindings = NA,                                  # TO DO: delete after unifying data format
    ParticipantID = paste(Experiment, ParticipantID, sep = ".")) %>%
  format_more()

d.exposure.Exp3 <- d.Exp3 %>% filter(Phase == "exposure") %>% excludeData()
d.test.Exp3 <- d.Exp3 %>% filter(Phase == "test")

rm(d.Exp2)
```

## Procedure: Comparison to Liu and Jaeger (2018)
The generation of exposure orders differed somewhat from that in LJ18. LJ18 generated two pseudo-randomized stimulus orders for exposure. These lists and their respective reverse orders formed four different exposure orders. Key binding---whether "X" and "M" corresponds to a word response or a non-word response, respectively, or vice versa---were counterbalanced across participants within each of these four orders, resulting in a total of 8 different exposure lists. The two pseudorandom orders in LJ18 were generated by repeatedly randomizing the order of stimuli until critical items, fillers, and catch trials were somewhat evenly distributed across the list. We took a more systematic approach, described in the main text, with the goal to create many randomized stimulus orders across participants, thereby creating cross-participant variability in nuisance factors not expected to affect test performance. 

Our catch trial procedure also differed somewhat from LJ18. In LJ18, participants had to answer the lexical decision question even on catch trials. This means participants had to press "X" or "M" even after pressing "B" to indicate that they had noticed the white dot. The trial would not proceed until "X" or "M" had been pressed. While piloting our experiments, we realized that this procedure created confusion. Thus, unlike Liu and Jaeger (2018), the catch trials in the present experiment ended when the participant pressed "B" whereas participants in Liu and Jaeger (2018) had to additionally answer the word vs. non-word question.

## Exclusions

```{r}
d.test.Exp3 %<>% run_exclusions(c("CISP-3"))
```

# Acoustic Analyses (NOTES)
Potential approach to modeling consequences of pen in exposure

 1. Get acoustic feature of the typical and atypical stims from our fricative database, both for exposure and test stimuli. Use only the main cue (CoG?). Could you do this?
 2. Fit the same regression I've used to analyze Exp 1a-c to the combined data of Exp1-ac with one change: instead of using mo(Condition.Test.Audio), use the phonetic cue (CoG?) as a predictor (either linear or as a monotonic spline, s(cue, bs = "mpi"). This will give us categorization functions for the pen in the hand and in the mouth. I can do this.
 3. For each exposure token (typical, atypical, pen in mouth or hand), this model can be used to predict p(response = "sh" | cue, pen location), using predict(model, newdata = exposure_tibble_with_cue_and_pen_values). I can do this.
 4. Get the perceived 'CoG' (or rather the CoG+pen percept) after the pen is taken into account. This can be done by inverting the model from step 3. Basically, for pen-in-the-mouth stimuli we would determine the CoG for which a pen-in-the-hand would have yielded the same p(sh) as the actual CoG of the stimulus combined with the fact that it was produced with a pen-in-the-mouth. 

  intercept_pim + slope.pim * CoG = intercept_pih + slope_pih * CoG_perceived <-->
  (intercept_pim + slope.pim * CoG  -  intercept_pih) / slope_pih = CoG_perceived

 5. This CoG_perceived would be the input e.g., belief-updating. In the simplest case, one would use the lexical endorsements of each participant as the ground truth and then update based on 1) those labels, 2) the CoG_perceived, 3) some initial estimate of the prior beliefs about s and sh along CoG, and 4) some range of kappa_0 and nu_0 {1, 10, 100}.

```{r}
# Acoustic parameters
exposure.acoustics <- read_csv("../data/acoustics/acoustic_information_exposure_items.csv")
test.acoustics <- read_csv("../data/acoustics/acoustic_information_test_items.csv")

CISP_Exp_CoG <- exposure.acoustics %>%
  filter(study == "Liu-Jaeger-2018",
         fricative %in% c("S", "SH")) %>%
  select(word, fricative, shift_percent, cue_raw_M1) %>%
  mutate(bias = case_when(
    fricative == "S" & shift_percent == 0 ~ "SH",
    fricative == "S" & shift_percent == 50 ~ "S",
    fricative == "SH" & shift_percent == 0 ~ "S",
    fricative == "SH" & shift_percent == 50 ~ "SH")) %>%
  rename(CoG = cue_raw_M1)

CISP_Test_CoG <- test.acoustics %>%
  select(word, cue_raw_M1) %>%
  rename(CoG = cue_raw_M1)

CoG_Exp_measurements <- CISP_Exp_CoG %>%
  group_by(fricative, shift_percent) %>%
  summarise(mean = mean(CoG),
            sd = sd(CoG))

rm(exposure.acoustics, 
   test.acoustics)

# Some visualizations for sanity checks
# Exposure_graph <- CISP_CoG %>%
#   filter(fricative != "?SSH") %>%
#   ggplot(aes(x = CoG,
#              color = fricative)) +
#   geom_density() +
#   facet_wrap(~bias) +
#   theme_bw()
# Exposure_graph
# 
# Test_graph <- CISP_Test_CoG %>%
#   ggplot(aes(x = as.numeric(word),
#              y = CoG,
#              label = word)) +
#   geom_label() +
#   theme_bw()
# Test_graph


## VALUES to use
# CoG for all test steps (ASHI-high)
CISP_Test_CoG

# CoG for all exposure items
CISP_Exp_CoG

# Means and SDs for exposure item types
CoG_Exp_measurements
```


