---
title: "Supplementary Information"
author: "Shawn Cummings and T. Florian Jaeger"
date: "\today"
output:
  word_document:
    toc: yes
    toc_depth: '4'
  fontsize: 10pt
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '4'
  pdf_document:
    fig_caption: yes
    fig_width: 7
    keep_tex: yes
    latex_engine: xelatex
    number_sections: yes
    toc: yes
    toc_depth: 4
geometry: margin=2cm
header-includes:
- \usepackage{booktabs}
- \usepackage{siunitx}
- \usepackage{tabto}
- \usepackage{soul}
- \usepackage{xcolor}
- \usepackage{placeins}
- \usepackage{lscape}
- \usepackage{animate}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
- \makeatletter\renewcommand{\fps@table}{!ht}\makeatother
- \setstcolor{red}
- \usepackage{sectsty}
- \sectionfont{\color{blue}}
- \subsectionfont{\color{blue}}
- \subsubsectionfont{\color{darkgray}}
---

```{r, include=FALSE}
library(tidyverse)
library(magrittr)    # pipes
library(lubridate)   # date conversion, etc.

library(brms)        # Bayesian GL(M)Ms
library(tidybayes)   # extract posterior from brmfits
library(modelr)      # create data grids
library(sjPlot)      # tables for Bayesian GL(M)Ms
library(broom)       # extracting information from GL(M)Ms
library(boot)        # easy logit() function

library(knitr)
library(linguisticsdown)  #IPA symbols
library(rstan)

# Setting up cmdstanr
# library(curl)
# if (has_internet()) install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library(cmdstanr)
# install_cmdstan()
```

```{r constants, include=FALSE}
source("constants.R")
```

```{r, include=FALSE}
opts_chunk$set(dev = 'png', dpi = 96,
               comment="", 
               echo=FALSE, warning=TRUE, message=TRUE,
               cache=FALSE, 
               size="small",
               tidy.opts = list(width.cutoff = 200),
               fig.width = fig.base_width, fig.height = fig.base_height, fig.align = "center")

def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

color_block = function(color) {
  function(x, options) sprintf('\\color{%s}\\begin{verbatim}%s\\end{verbatim}\\color{black}',
                               color, x)
}
knitr::knit_hooks$set(error = color_block('red'))
knitr::knit_hooks$set(warning = color_block('orange'))
```

```{r functions to consolidate}
format_more <- 
  . %>%
  # Potentially move these into the format function
  rename_with(~ gsub("Answer.", "", .x)) %>%
  rename(
    Participant.AudioType = audio_type,
    Participant.AudioStall = audio_stall,
    Participant.VideoStall = video_stall,
    Talker.Sex = sex,
    Talker.PronunciationShift = ssh2,
    Talker.PronunciationProperties = pronun,
    Talker.SpeechDescription = speaker) %>%
  add_exclusions() %>%
  mutate(
    Condition.Exposure.Pen = NA,
    Condition.Exposure.LexicalLabel = NA,
    Response.ASHI = ifelse(Response == "ASHI", 1, 0)) %>%
  select(
    Experiment, ParticipantID, starts_with("Participant."),
    Condition.Exposure.Pen, Condition.Exposure.LexicalLabel, 
    Condition.Test.Audio, Condition.Test.Pen, Condition.Test.OriginalLabel, Condition.Test.Keybindings,
    Block, Trial, ItemID, 
    Response, Response.ASHI, Response.RT, Response.CatchTrial,
    starts_with("Talker"),
    starts_with("Duration"),
    starts_with("Exclude")) 
```

# TO DO:

## Priority HIGHEST

 * in add_exclusions, there is commented out code at the top of the function. Why is it commented out, and how are we removing participants for technical difficult if not there?

## Priority MEDIUM

 * make sure that data formatting *function* is in *this* repo (raw data should *not* be in this repo)
 * consider adding renaming of variables into formatting function, removing it from early code chunk:
 
 rename(
    Participant.AudioType = Answer.audio_type,
    Participant.AudioStall = Answer.audio_stall,
    Participant.VideoStall = Answer.video_stall,
    Talker.Sex = Answer.sex,
    Talker.PronunciationShift = Answer.ssh2,
    Talker.PronunciationProperties = Answer.pronun,
    Talker.SpeechDescription = Answer.speaker)
 
 * consolidate constants.R and functions.R. It's currently unclear what's in which and why.
 * fill in all survey questions in procedure section for Exp 1a-c, and provide some summary of participants' responses where relevant.


# Context statement
This document contains the data preparation, visualization, and analyses reported in the main text. As of 2022, the Human Language Processing Lab, University of Rochester, is committed to producing articles and supplementary information in the form of R Markdown documents whenever possible. This particular project grew out of a yearlong undergraduate research class (BCS 206 "Undergraduate Research in Cognitive Science"). To accommodate differences in familiarity with R programming, and to facilitate project workflow, the authors agreed to write the main text in a common word processing software, and to provide this R Markdown document as supplementary information.

# Experiments 1a-c
Experiment 1a was conducted between 1/20-22/2021. Experiment 1b was conducted between 3/03-04/2021. Experiment 1c was conducted between 6/03-05/2021. 

## Data import

```{r}
load("../data/Experiment-NORM-A-before-exclusions.RData") 
d.Exp1a <- 
  d.test.A %>%
  mutate(
    Experiment = "CISP-1a",
    ParticipantID = paste(Experiment, ParticipantID, sep = "."))
 
load("../data/Experiment-NORM-B-before-exclusions.RData") 
d.Exp1b <- 
  d.test.B %>%
  mutate(
    Experiment = "CISP-1b",
    ParticipantID = paste(Experiment, ParticipantID, sep = "."))

load("../data/Experiment-NORM-C-before-exclusions.RData") 
d.Exp1c <- 
  d.test.C %>%
  mutate(
    Experiment = "CISP-1c",
    ParticipantID = paste(Experiment, ParticipantID, sep = "."))

d.LJ18.test <- 
  read.csv("../data/Liu Jaeger 2018/Liu-Jaeger-2018-test-1-s2.0-S0010027718300118-mmc2.csv") %>%
  # Filter to norming experiment
  filter(
    Condition == 'Filler') %>%
  mutate(
    Experiment = factor('LJ18-NORM'),
    ParticipantID = as.factor(paste0("LJ18.", Subject)), 
    Condition.Test.Audio = Step, 
    Condition.Test.Pen = "audio-only",
    Condition.Test.OriginalLabel = NA,
    Response = factor(case_when(Response == "SH" ~ "ASHI", Response == "S" ~ "ASI")),
    # Blocks were 6 trials per block in LJ18 but 12 in CISP, so we re-calculate
    # blocks for LJ18 to be blocks of 12 trials.
    Block = Trial %/% 12 + 1, 
    Trial = Trial + 1,
    across(c(Condition.Test.Pen, Condition.Test.OriginalLabel), factor))

d.test <- 
  bind_rows(d.Exp1a, d.Exp1b, d.Exp1c, d.LJ18.test) %>%
  format_more()

rm(d.test.A, d.test.B, d.test.C)
```

## Materials: Selection of acoustic continuum steps
As described in the main text, we aimed to maximize the power to detect effects---like that oc the pen in the mouth---along the *asi-ashi* continuum. Specifically, we aimed to select one step that, across all other manipulations, would yield approximated 25% *ashi* responses, four steps that would yield close to 50% *ashi* responses, and one step that would yield 75% *ashi* responses.

The intention for Experiment 1a was to employ the exact same acoustic steps as in @liu-jaeger2018: 12, 14, 15, 16, 17, and 19, where higher numbers indicate acoustically more ashi-like steps. However, a labelling mistake resulted in the steps being internally named with higher numbers indicating proportion of asi, rather than ashi. The actual steps that were used in Experiment 1a were 13, 15, 16, 17, 18, 20 unintentionally shifting the test continuum 1 step towards the ashi end, compared to @liu-jaeger2018. As we report below, Experiment 1a yielded overall more asi than ashi responses. Experiment 1b thus attempted to expand the test stimuli towards the ashi end of the continuum. However, as we still had not discovered the labeling mistake, we ended up expanding the continuum even further towards the asi end instead, with steps 10, 13, 14, 15, 16, 20. At this point, we identified the labeling mistake. Experiment 1c employed steps 13, 18, 19, 20, 21, and 26. We emphasize that the location of the test steps is not critical for Experiments 1a-c.

## Procedure: Further details on exit survey
<!-- TO DO SHAWN: could you fill in more information about the questions we asked, including a full list of questions? -->

For Experiment 1b, we made minor changes to the survey. We removed one question about audio quality which asked participants to rate the quality of their audio equipment as "bad", "good", "professional", etc. Previous analyses in our lab have found that the subjective nature of this question makes it hard to interpret. And, in order to encourage the participants to answer survey questions truthfully, we emphasized that they would get compensated independent of their answers, and that truthful answers would greatly help us with the interpretation of results. <!-- TO DO: please check whether this is all correct. I belive we have detailed notes about these changes both in an RMD file I created back then, and in the Javascript / survey code itself. -->

For Experiment 1c, we revised our questions about internet connectivity. Specifically, we changed the two questions that asked about video or sound issues during the experiment. We clarified that these questions were asking solely about technical issues, rather than any oddities between the alignment of the video and audio (as separate questions already assessed that aspect). The revised questions were introduced by the following statement: "The videos and sounds in this experiment were manipulated by aligning the same video with different sound sources. As a consequence, you might have noticed some 'jumps' or slightly odd-looking moments in the video. Here we are interested in *potential technical issues with the internet connection* beyond any oddities you might have noticed about how the video and sound aligned." (emphasis in original) Then two questions assessed whether the videos or sounds failed to load or stopped and restarted playing during exposure. As these revised questions explicitly mentioned that the videos and sounds had been manipulated, they were moved towards the end of the survey, so that they followed any questions that inquired about the pronunciation of the talker in the video (recall that participants could not go back to previously answered questions). <!-- TO DO: please check whether this is all correct. I belive we have detailed notes about these changes both in an RMD file I created back then, and in the Javascript / survey code itself. -->

## Exclusions

```{r exclusions, fig.width=4*fig.base_width, fig.height=fig.base_height }
run_exclusions <- function(data, experiment) {
  data %<>% filter(Experiment %in% experiment)
  print(
    data %>% 
      distinct(Experiment, ParticipantID, Exclude_Participant.Reason) %>% 
      group_by(Experiment, Exclude_Participant.Reason) %>% 
      tally() %>% 
      group_by(Experiment) %>%
      mutate(Percent = percent(n / sum(n))))
  
  exclusionPlot(data)
  
  data %<>% 
    excludeData()
  
  message(
    "\nData submitted for analysis contains ", 
    nrow(data %>% filter(is.na(Response.ASHI))),
    " missing observations (",
    percent(nrow(data %>% filter(is.na(Response.ASHI))) / nrow(data)),
    "), leaving ",
    nrow(data %>% filter(!is.na(Response.ASHI))),
    " observations from ",
    data %>% filter(!is.na(Response.ASHI)) %>% pull(ParticipantID) %>% unique() %>% length(),
    " participants from ",
    data %>% filter(!is.na(Response.ASHI)) %>% pull(Experiment) %>% unique() %>% length(),
    " experiment(s).")
  
  data %>%
    filter(!is.na(Response.ASHI))
}

d.test.Exp1 <-
  d.test %>% 
  run_exclusions(c("CISP-1a", "CISP-1b", "CISP-1c"))

d.test %<>%
  excludeData() %>%
  filter(!is.na(Response.ASHI))
```

## Analyses

```{r}
# Prep for analysis
prep_for_analysis <- function(data) {
  data %>%
    { if (length(unique(.$Experiment)) > 1) 
      mutate(
        .,
        Experiment = 
          "contrasts<-"(factor(Experiment), , contr.sum(length(unique(.$Experiment))))) else . } %>%
    { if (all(!is.na(.$Condition.Test.Pen), !is.na(.$Condition.Test.OriginalLabel))) 
      mutate(
        .,
        Condition.Test.Pen = 
          "contrasts<-"(factor(Condition.Test.Pen), , cbind("M" = c(-0.5, 0.5))),
        Condition.Test.OriginalLabel = 
          "contrasts<-"(factor(Condition.Test.OriginalLabel), , cbind("SH" = c(-0.5, 0.5)))) else . } %>%
    mutate(Block = Block - 1) %>%
    select(Experiment, 
           Condition.Test.OriginalLabel, Condition.Test.Pen, Block, Condition.Test.Audio, 
           ParticipantID, Response.ASHI) 
}

fit_test_model <- function(data, experiment, audio_only = if ("LJ18-NORM" %in% experiment) T else F) {
  my_formula <- if (audio_only) {
    bf(Response.ASHI ~
         1 + mo(Block) * mo(Condition.Test.Audio) +
         (1 + mo(Condition.Test.Audio) | ParticipantID))
  } else {
    bf(paste(
      "Response.ASHI ~",
      "1 + Condition.Test.OriginalLabel * Condition.Test.Pen * mo(Block) * mo(Condition.Test.Audio)",
      if (length(unique(experiment)) > 1) "* Experiment +" else "+",
      "(1 + Condition.Test.OriginalLabel * Condition.Test.Pen * mo(Condition.Test.Audio) | ParticipantID)"))
  }
  
  m <- brm(
    my_formula,
    data = 
      data %>%
      filter(Experiment %in% experiment) %>% 
      prep_for_analysis(),
    family = "bernoulli",
    prior = my_priors,
    sample_prior = "yes",
    backend = "cmdstanr",
    chains = 4, 
    warmup = if (length(unique(data$Experiment)) > 1) 2000 else 1000,
    iter = if (length(unique(data$Experiment)) > 1) 3000 else 2000,
    control = list(adapt_delta = if (length(unique(data$Experiment)) > 1) .95 else .8),
    cores = min(parallel::detectCores(), 4), 
    threads = threading(threads = 4),
    file = paste("../models/Exp", paste(experiment, collapse = "-"), sep = "-"))
  
  return(m)
}

my_hypotheses <- function(m, experiment, plot = F) { 
  format <-  
    . %>%
    rename(BF = Evid.Ratio) %>%
    mutate(
      Experiment = experiment,
      across(
        c("Estimate", "Est.Error", starts_with("CI"), "Post.Prob"),
        ~ signif(.x, 3)),
      BF = ifelse(is.infinite(BF), paste(">", ndraws(m)), as.character(round(BF, 1)))) %>% 
    relocate(Experiment, everything())

  # mo() operators imply that the effects of the other variables are assessed at the reference level of the
  # monotonic predictor. For Block, this is exactly what we want: evaluation of effects in the first Block.
  # However, for the continuum, we'd like to assess effects in the middle of the continuum. This is taken 
  # into account below.
  l <- list(
    { h.pen <- hypothesis(
      m, 
      c(
        # There are 5 continuum steps above the baseline, so we add 2.5 * the interaction of continuum and the 
        # effect of interest to the effect of interest. (a more precise estimate could be obtained by following
        # Figure 1 in Bürkner & Charpentier, which takes into account the specific simo estimates).
        "b_Condition.Test.PenM  + 2.5 * bsp_moCondition.Test.Audio:Condition.Test.PenM < 0",
        "bsp_moCondition.Test.Audio:Condition.Test.PenM < 0",
        "b_Condition.Test.OriginalLabelSH:Condition.Test.PenM + 2.5 * bsp_moCondition.Test.Audio:Condition.Test.OriginalLabelSH:Condition.Test.PenM < 0",
        "bsp_moCondition.Test.Audio:Condition.Test.OriginalLabelSH:Condition.Test.PenM < 0"),
      class = NULL) } %>%
      .[["hypothesis"]] %>% 
      mutate(Hypothesis = c(
        "Pen location Mouth -> fewer ASHI-responses",
        "Pen effect increases for more ASHI-like acoustic input",
        "Pen effect increases for visually ASHI-biased input",
        "Pen effect increases even more when acoustic and visual input is ASHHI-biased")) %>%
      format() %>%
      kable(caption = "Effects of pen location."),
    { h.cues <- hypothesis(
      m, 
      c("bsp_moCondition.Test.Audio > 0", 
        "b_Condition.Test.OriginalLabelSH + 2.5 * bsp_moCondition.Test.Audio:Condition.Test.OriginalLabelSH > 0",
        "bsp_moCondition.Test.Audio:Condition.Test.OriginalLabelSH = 0"), 
      class = NULL, scope = "standard") } %>%
      .[["hypothesis"]] %>% 
      mutate(Hypothesis = c(
        "Acoustic continuum more ASHI-like -> more ASHI-responses",
        "Visual bias ASHI -> more ASHI-responses",
        "Acoustic and visual bias effects are independent")) %>% 
      format() %>%
      kable(caption = "Effects of acoustic continuum and visual bias."),
    { h.block <- hypothesis(
      m, 
      c(
        "bsp_moBlock:Condition.Test.PenM + 2.5 * bsp_moBlock:moCondition.Test.Audio:Condition.Test.PenM = 0",
        "bsp_moBlock:moCondition.Test.Audio = 0", 
        "bsp_moBlock:Condition.Test.OriginalLabelSH + 2.5 * bsp_moBlock:moCondition.Test.Audio:Condition.Test.OriginalLabelSH = 0"),
      class = NULL) } %>%
      .[["hypothesis"]] %>% 
      mutate(Hypothesis = c(
        "Pen effect is stable over blocks",
        "Continuum effect is stable over blocks",
        "Visual bias effect is stable over blocks")) %>%
      format() %>%
      kable(caption = "Changes across blocks."))
  
  if (plot) {
    plot(h.pen)
    plot(h.cues)
    plot(h.block)
  }
  return(l)
}

plot_model_predictions <- function(m) {
  plot(conditional_effects(m, method = "posterior_linpred"), ask = F)
}

plot_model_predictions_for_paper <- function(m) {
  conditional_effects(
    m, 
    method = "posterior_linpred")
}

plot_data <- function(data, experiment, background_experiment = NULL) {
  require(dplyr)
  require(ggplot2)
  require(cowplot)
  
  shared_stats <- function(data = NULL, color = "black", dodge = .5) 
    list(
      stat_summary(
        data = data, fun = mean, geom = "line", 
        position = position_dodge(dodge), alpha = .5, color = color),
      stat_summary(
        data = data, fun = mean, geom = "point", 
        position = position_dodge(dodge), size = 1, color = color),
      stat_summary(
        data = data, fun.data = mean_cl_boot, geom = "linerange", 
        position = position_dodge(dodge), linetype = 1, alpha = .65, color = color))
  shared_formatting <- 
    list(
      scale_y_continuous('Proportion "ASHI"-responses'),
      scale_shape_manual(
        "Pen location", 
        breaks = levels.test.pen_locations, labels = labels.test.pen_locations, values = shapes.test.pen_locations),
      scale_linetype_manual(
        "Pen location", 
        breaks = levels.test.pen_locations, labels = labels.test.pen_locations, values = linetypes.test.pen_locations),
      facet_wrap(~ Experiment, ncol = 1))
  
  aggregate <- function(data, ..., e = experiment) {
    groups = enquos(...)
    data %>%
      filter(Experiment %in% e) %>%
      mutate(Experiment = gsub("CISP-", "Exp ", Experiment)) %>%
      droplevels() %>%
      mutate(Condition.Test.Pen = ifelse(Condition.Test.Pen == "audio-only", "H", as.character(Condition.Test.Pen))) %>%
      group_by(!!! groups) %>%
      summarise(Response.ASHI = mean(Response.ASHI)) 
  }
  
  p <- list()
  p[[1]] <- 
    data %>% 
    aggregate(Experiment, ParticipantID, Condition.Test.Pen, Condition.Test.Audio) %>%
    ggplot(aes(x = Condition.Test.Audio, y = Response.ASHI, shape = Condition.Test.Pen, linetype = Condition.Test.Pen)) +
    scale_x_continuous(
      'Acoustic continuum', 
      breaks = as.integer(append(range(data$Condition.Test.Audio), mean(range(data$Condition.Test.Audio))))) +
    shared_stats() +
    shared_formatting + 
    coord_cartesian(xlim = range(data$Condition.Test.Audio), ylim = c(.1, .9))
  
  if (!is.null(background_experiment))
    p[[1]] <- 
    p[[1]] + 
    shared_stats(
        data = data %>%
          aggregate(Experiment, ParticipantID, Condition.Test.Pen, Condition.Test.Audio, 
                    e = background_experiment) %>% 
          ungroup() %>%
          select(-Experiment) %>%
          crossing(Experiment = gsub("CISP-", "Exp ", experiment)), 
        dodge = 1, 
        color = "gray75")
  
    p[[2]] <- 
    data %>%
    aggregate(Experiment, ParticipantID, Condition.Test.Pen, Condition.Test.OriginalLabel) %>%
    ggplot(aes(x = Condition.Test.OriginalLabel, y = Response.ASHI, 
               shape = Condition.Test.Pen, linetype = Condition.Test.Pen,
               group = Condition.Test.Pen)) +
    shared_stats(dodge = .25) +
    shared_formatting + 
    scale_x_discrete('Visual bias') +
    # scale_color_manual(
    #   'Visual bias', 
    #   breaks = levels.test.visual_labels, labels = labels.test.visual_labels, values = colors.test.visual_labels) +
    coord_cartesian(ylim = c(.1, .9)) +
    theme(legend.position = "none")
  
  if (!is.null(background_experiment) & !("LJ18-NORM" %in% background_experiment))
    p[[2]] <- 
    p[[2]] + 
      shared_stats(
        data = data %>%
          aggregate(Experiment, ParticipantID, Condition.Test.Pen, Condition.Test.OriginalLabel, 
                    e = background_experiment) %>% 
          ungroup() %>%
          select(-Experiment) %>%
          crossing(Experiment = gsub("CISP-", "Exp ", experiment)), 
        dodge = .5, 
        color = "gray75")

  # p[[3]] <- 
  #   data %>%
  #   aggregate(Experiment, ParticipantID, Condition.Test.Pen, Condition.Test.Audio, Condition.Test.OriginalLabel) %>%
  #   ggplot(aes(x = Condition.Test.Audio, y = Response.ASHI, color = Condition.Test.OriginalLabel, 
  #              shape = Condition.Test.Pen, linetype = Condition.Test.Pen)) +
  #   scale_x_continuous('Acoustic continuum', limits = range(data$Condition.Test.Audio)) +
  #   scale_color_manual(
  #     'Visual bias', 
  #     breaks = levels.test.visual_labels, labels = labels.test.visual_labels, values = colors.test.visual_labels) +
  #   shared_components +
  #   coord_cartesian(xlim = range(data$Condition.Test.Audio))
  #   theme(legend.position = "none")
  
  cowplot::plot_grid(
    plotlist = p, 
    align = "hv", axis = "btrl", 
    ncol = length(p), labels = paste0(LETTERS[1:length(p)], ")"),
    rel_widths = c(.7, .3), rel_heights = 1.5)
}
```

```{r}
p <- plot_data(d.test, experiment = c("CISP-1a", "CISP-1b", "CISP-1c"), background_experiment = "LJ18-NORM")
plot(p)
  
ggsave(
  p,
  file = "../figures/Experiment 1a-c.png", 
  width = fig.base_width * 3,
  height = fig.base_height * 3 + .25)
```


### Experiment 1a

```{r results='markup'}
m.Exp1a <- fit_test_model(d.test.Exp1, "CISP-1a")
my_hypotheses(m.Exp1a, experiment = "Exp 1a") %>% map(print) -> TEMP

# Sanity check to see whether there are other significant effects, not included in hypothesis tests
summary(m.Exp1a)$fixed %>% filter(map2(`l-95% CI`, `u-95% CI`, ~ !between(0, .x, .y)) %>% unlist())
plot_model_predictions(m.Exp1a)
```


### Experiment 1b

```{r}
m.Exp1b <- fit_test_model(d.test.Exp1, "CISP-1b")
my_hypotheses(m.Exp1b, experiment = "Exp 1b") %>% map(print) -> TEMP
# Sanity check to see whether there are other significant effects, not included in hypothesis tests
summary(m.Exp1b)$fixed %>% filter(map2(`l-95% CI`, `u-95% CI`, ~ !between(0, .x, .y)) %>% unlist())

plot_model_predictions(m.Exp1b)
```

### Experiment 1c

```{r}
m.Exp1c <- fit_test_model(d.test.Exp1, "CISP-1c")
my_hypotheses(m.Exp1c, experiment = "Exp 1c")  %>% map(print) -> TEMP
# Sanity check to see whether there are other significant effects, not included in hypothesis tests
summary(m.Exp1c)$fixed %>% filter(map2(`l-95% CI`, `u-95% CI`, ~ !between(0, .x, .y)) %>% unlist())

plot_model_predictions(m.Exp1c)
```
### Liu and Jaeger (2018)
For comparison, we also analyzed Liu and Jaeger's norming experiment with the same analysis approach employed in the present study.

```{r}
d.test.LJ18 <- 
  d.test %>%
  run_exclusions("LJ18-NORM")

m.LJ18 <- fit_test_model(d.test.LJ18, "LJ18-NORM")
my_LJ18_hypothesis <- function(m, experiment = "LJ18-NORM") {
  format <-  
    . %>%
    rename(BF = Evid.Ratio) %>%
    mutate(
      Experiment = experiment,
      across(
        c("Estimate", "Est.Error", starts_with("CI"), "Post.Prob"),
        ~ signif(.x, 3)),
      BF = ifelse(is.infinite(BF), paste(">", ndraws(m)), as.character(round(BF, 1)))) %>% 
    relocate(Experiment, everything())
  
  hypothesis(
    m, 
    c("bsp_moCondition.Test.Audio > 0",
      "bsp_moBlock:moCondition.Test.Audio = 0"), 
    class = NULL, scope = "standard") %>%
    .[["hypothesis"]] %>% 
    mutate(
      Experiment = "LJ18-NORM",
      Hypothesis = c(
        "Acoustic continuum more ASHI-like -> more ASHI-responses",
        "Continuum effect is stable over blocks")) %>% 
    format() %>%
    kable(caption = "Effects of acoustic continuum.")
}

my_LJ18_hypothesis(m.LJ18)
# Sanity check to see whether there are other significant effects, not included in hypothesis tests
summary(m.LJ18)$fixed %>% filter(map2(`l-95% CI`, `u-95% CI`, ~ !between(0, .x, .y)) %>% unlist())

plot_model_predictions(m.LJ18)

d.test.LJ18 %>% 
  data_grid(ParticipantID, Condition.Test.Audio, Block = 1) %>%
  add_epred_draws(m.LJ18, re_formula = NULL) %>%
  ggplot(aes(x = Condition.Test.Audio, y = Response.ASHI)) +
  stat_lineribbon(aes(y = .epred), color = "black") +
  stat_summary(
    data = 
      d.test.LJ18 %>% 
      filter(Block == 1) %>%
      group_by(ParticipantID, Condition.Test.Audio) %>%
      summarise(Response.ASHI = mean(Response.ASHI)),
    geom = "pointrange",
    color = "black") +
  scale_fill_grey()
```

# Experiments 2 and 2b
We conducted two experiments that were designed to test whether listeners need to see the effects of the pen on the articulators *during the production of the fricative*, or whether the presence of a pen during the production of a fricative is sufficient to cause the effects observed in Experiments 1a-c. To this end, Experiments 2 and 2b introduced a black box that occluded the talker's mouth during the articulation of the fricative (see main text for details). The two experiments were identical except that Experiment 2b introduced an additional task intended to assure that participants paid attention to the videos (rather than just the audio). This change in procedure from Experiment 2 to 2b was intended to address an alternative explanation for the results of Experiment 2. As reported below, Experiment 2 did not find the effects of pen location that were present in Experiments 1a-c. This raised the question as to whether participants in Experiment 2 failed to pay attention to the video (unlike in Experiments 1a-c). The additional task in Experiment 2b addressed this possibility.

Experiment 2 was conducted between 7/14-15/2021. Experiment 2b was conducted between 7/23-24/2021.

## Data import

```{r}
load("../data/Experiment-NORM-D-before-exclusions.RData") #named d.test.D
load("../data/Experiment-NORM-E-before-exclusions.RData") #named d.test.E

d.Exp2 <- 
  d.test.D %>%
  mutate(
    Experiment = "CISP-2",
    ParticipantID = paste(Experiment, ParticipantID, sep = "."))
 
d.Exp2b <- 
  d.test.E %>%
  mutate(Participant.Age = as.double(Participant.Age)) %>%
  mutate(
    Experiment = "CISP-2b",
    ParticipantID = paste(Experiment, ParticipantID, sep = "."))

d.test.Exp2 <- 
  bind_rows(d.Exp2, d.Exp2b) %>%
  format_more()

rm(d.test.D, d.test.E)
```

## Procedure
Experiment 2 employed the exact same tasks as Experiment 1a-c. Experiment 2b, however, introduced an additional task. Participants were asked to press SPACE whenever the pen was in the talker's mouth. After pressing SPACE, participants had to answer whether they heard *asi* or *ashi*, as in all preceding experiments. Figure \@ref(fig:XXX) shows a screenshot of the specific instructions. 

<!-- TO DO: Shawn, can we add the screen shot from your email here, or perhaps a screen shot of the entire screen, incl. the part you had in your email -->

## Exclusions
Figure \@ref(fig:XXX) summarized the exclusions for Experiment 2 and 2b. Of note is the high exclusion rate for Experiment 2b, for which almost one fourth of all participants stated after the experiment that they had not been wearing head phones. This deterioration of data quality for experiments conducted over Mechanical Turk post 2020 was also observed in other experiments conducted in our lab during the same time period. Like in the present case, deterioration of data quality tended to be particularly pronounced in those other studies when we conducted a series of experiments, One possible explanation is our recruitment criterion, which only allowed participants to see the experiment if they had *not* participated in any previous experiment of the series. This successively reduces the participant pool, potentially making the experiment vulnerable to increasingly less cooperative participants. 

This motivated our switch to the Prolific crowdsourcing experiments for subsequent experiments. Experiment 2b was the last experiment we conducted over Mechanical Turk. <!-- TO DO: correct? -->

```{r}
d.test.Exp2 %<>% run_exclusions(c("CISP-2", "CISP-2b"))
```

### Experiment 2

```{r}
p <- 
  plot_data(
    bind_rows(d.test.Exp1, d.test.Exp2), 
    experiment = "CISP-2", background_experiment = "CISP-1c")
plot(p)

ggsave(
  p,
  file = "../figures/Experiment 2.png", 
  width = fig.base_width * 3,
  height = fig.base_height + .5)
```

```{r results='markup'}
m.Exp2 <- fit_test_model(d.test.Exp2, experiment = "CISP-2")
my_hypotheses(m.Exp2, experiment = "Exp 2") %>% map(print) -> TEMP
plot_model_predictions(m.Exp2)
```

### Comparison of Experiment 2a against Experiment 1c

```{r results='markup'}
m.Exp2vsExp1c <- fit_test_model(data = bind_rows(d.test.Exp1, d.test.Exp2), experiment = c("CISP-1c", "CISP-2"))
# Does Experiment 2 have fewer ASHI responses (in the middle of the continuum)? YES, somewhat.
hypothesis(m.Exp2vsExp1c, "b_Experiment1  + 2.5 * bsp_moCondition.Test.Audio:Experiment1 < 0", class = NULL)
# Is there still an affect of pen across the two experiments? YES
hypothesis(m.Exp2vsExp1c, "b_Condition.Test.PenM  + 2.5 * bsp_moCondition.Test.Audio:Condition.Test.PenM < 0", class = NULL)
# And, is that effect of pen smaller in Experiment 2? NOT REALLY?!?!
hypothesis(m.Exp2vsExp1c, "b_Condition.Test.PenM:Experiment1 > 0", class = NULL)
hypothesis(m.Exp2vsExp1c, "b_Condition.Test.PenM:Experiment1  + 2.5 * bsp_moCondition.Test.Audio:Condition.Test.PenM:Experiment1 > 0", class = NULL)

summary(m.Exp2vsExp1c)$fixed %>% filter(map2(`l-95% CI`, `u-95% CI`, ~ !between(0, .x, .y)) %>% unlist())
```

### Experiment 2b
We first analyzed the accuracy of SPACE presses. Participants were significantly above chance in detecting the pen in the mouth of the talker (75% accurate). Participants were, however, much more accurate when the pen was not in the mouth of the talker (95%). This asymmetry is not particularly surprising: correct detection of the pen in the mouth required a key press, whereas correct detection that the pen was not in the mouth (but rather in the hand) required no action at all.

```{r}
d.test.Exp2 %>%
  mutate(Reponse.CatchCorrect = ifelse(Response.CatchTrial == (Condition.Test.Pen == "mouth"), 1, 0)) %>%
  ggplot(aes(x = Condition.Test.Pen, y = Reponse.CatchCorrect, shape = Condition.Test.Pen)) +
  stat_summary(fun.data = mean_cl_boot, geom = "pointrange") +
  scale_x_discrete(
    "Pen location", 
    breaks = levels.test.pen_locations, 
    labels = labels.test.pen_locations) +
  scale_y_continuous("Proportion correct responses about pen location") +
  scale_shape_manual(
    "Pen location", 
    breaks = levels.test.pen_locations, labels = labels.test.pen_locations, values = shapes.test.pen_locations)
```

Next, we turn to participants categorization responses---i.e., whether participants heard *asi* or *ashi*. Figure \@ref(fig:results-exp2b) summarizes participants' categorization responses. Compared to Experiment 2, participants in Experiment 2b exhibited noticeably weaker effects of the acoustic continuum (more shallow slope in Figure \@ref(fig:results-exp2b)a). This suggests a trade-off introduced by the secondary task in Experiment 2b: either because participants focused more on the visual input, or because the categorization response was delivered *after* the response to the visual stimulus (SPACE press), participants' responses were less affected by the acoustic continuum. Critically, however, Experiment 2b replicates all effects found in Experiment 2. It is worth noting though that, in line with the idea of a trade-off, the effects of pen location and the visual bias were more pronounced in Experiment 2b, compared to 2. 

(ref:results-exp2b) Summary of participants’ responses in Experiments 2b, depending on pen location and acoustic continuum step (Panel A) or visual bias (Panel B). For comparison, the results from Experiment 2 are shown in the background. The two experiments were identical except for the secondary task introduced in Experiment 2b.

```{r results-exp2b, fig.width=fig.base_width * 3, fig.height=fig.base_height + .5 fig.cap="(ref:results-exp2b)"}
p <-
  plot_data(
    bind_rows(d.test.Exp1, d.test.Exp2), 
    experiment = "CISP-2b", background_experiment = "CISP-2")
plot(p)

ggsave(
  p,
  file = "../figures/Experiment 2b.png", 
  width = fig.base_width * 3,
  height = fig.base_height + .5)
```

```{r}
m.Exp2b <- fit_test_model(d.test.Exp2, "CISP-2b")
my_hypotheses(m.Exp2b, experiment = "Exp 2b") %>% map(print) -> TEMP
plot_model_predictions(m.Exp2b)
```

# Experiment 3
Experiment 3 was conducted

## Data import

```{r}
rm(d.Exp2)
load("../data/Experiment-3-before-exclusions.RData") 
d.Exp3 <- 
  d.Exp2 %>%
  mutate(
    Experiment = "CISP-3",
    ParticipantID = paste(Experiment, ParticipantID, sep = ".")) %>%
  format_more()

rm(d.Exp2)
```

## Procedure: Comparison to Liu and Jaeger (2018)
The generation of exposure orders differed somewhat from that in LJ18. LJ18 generated two pseudo-randomized stimulus orders for exposure. These lists and their respective reverse orders formed four different exposure orders. Key binding---whether "X" and "M" corresponds to a word response or a non-word response, respectively, or vice versa---were counterbalanced across participants within each of these four orders, resulting in a total of 8 different exposure lists. The two pseudorandom orders in LJ18 were generated by repeatedly randomizing the order of stimuli until critical items, fillers, and catch trials were somewhat evenly distributed across the list. We took a more systematic approach, described in the main text, with the goal to create many randomized stimulus orders across participants, thereby creating cross-participant variability in nuisance factors not expected to affect test performance. 

Our catch trial procedure also differed somewhat from LJ18. In LJ18, participants had to answer the lexical decision question even on catch trials. This means participants had to press "X" or "M" even after pressing "B" to indicate that they had noticed the white dot. The trial would not proceed until "X" or "M" had been pressed. While piloting our experiments, we realized that this procedure created confusion. Thus, unlike Liu and Jaeger (2018), the catch trials in the present experiment ended when the participant pressed "B" whereas participants in Liu and Jaeger (2018) had to additionally answer the word vs. non-word question.

## Exclusions

```{r}
d.Exp3 %<>% run_exclusions(c("CISP-3"))
```
