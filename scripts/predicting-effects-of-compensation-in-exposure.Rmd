---
title: "Untitled"
author: "Shawn and Florian"
date: "03-20-25"
output: pdf_document
header-includes:
- \usepackage{float}
- \usepackage{booktabs}
- \usepackage{siunitx}
- \usepackage{tabto}
- \usepackage{soul}
- \usepackage{xcolor}
- \usepackage{placeins}
- \usepackage{lscape}
- \usepackage{animate}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
- \makeatletter\renewcommand{\fps@table}{!ht}\makeatother
- \setstcolor{red}
- \usepackage{sectsty}
- \sectionfont{\color{blue}}
- \subsectionfont{\color{blue}}
- \subsubsectionfont{\color{darkgray}}
---

## TO DO
This script in need of commenting/cleaning, but

 1. Align PIM/PIH inferred CoG's with a better pipeline than the current
 clunky pivot_wider method:
   -coerce the brm coefs into a glm
   -use that glm along with the investr package to predict x's given y's
       -investr::invest.glm(model, y)
  1b. Check whether that already makes the predicted difference functions
  (between inferred CoG in PIM vs PIH) monotonic across CoG. If not, figure 
  out why.

 2. Determine some priors that better align with 1c norm behavior. two
 methods here:
   -single-param optim() using the current priors (which are inferred from
    production data) and adding noise.
   -Use MVBeliefUpdatr::infer_NIW_ideal_adaptor on the exposure-test data.

 3. Fit predictions of belief updating (specifically the reduction of effect
 when PIM) to the actual behavioral data.

```{r libraries}
library(tidyverse)
library(data.table)
library(magrittr)
library(rlang)
library(assertthat)

library(cowplot)
library(gganimate)

library(brms)

# devtools::install_github("hlplab/MVBeliefUpdatr")
library(MVBeliefUpdatr)

source("functions.R")

RESET_MODELS <- FALSE
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment="",
  echo=FALSE, warning=TRUE, message=TRUE,
  cache=FALSE,
  size="small",
  dev = 'png', dpi = 96,
  tidy.opts = list(width.cutoff = 200),
  fig.width = fig.base_width, fig.height = fig.base_height,
  fig.pos = "!ht", fig.align = "center")

def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})

color_block = function(color) {
  function(x, options) sprintf('\\color{%s}\\begin{verbatim}%s\\end{verbatim}\\color{black}',
                               color, x)
}
knitr::knit_hooks$set(error = color_block('red'))
knitr::knit_hooks$set(warning = color_block('orange'))
```

# Data [TO DO: add Liu & Jaeger (2018) data]

```{r load-data}
# Import acoustics (including just CoG for now)
d.acoustics <-
  rbind(
    read_tsv("../materials/Annotated/s_segments.txt"),
    read_tsv("../materials/Annotated/sh_segments.txt"),
    read_tsv("../materials/Annotated/test_segments.txt")) %>%
  filter(segment %in% c("S", "SH", "?")) %>%
  mutate(
    type = 
      factor(
        case_when(
          grepl("50", source) == T ~ "shifted",
          grepl("_0", source) == T ~ "typical",
          grepl("test", source) == T ~ "test"),
        levels = c("typical", "shifted", "test")),
    cog = as.numeric(cog)) %>%
  select(segment, word, cog, type)

# Perception from all experiments
d.perception <-
  read.csv("../data/CISP_data.csv") %>%
  # Run formatting from Cummings et al 2025
  mutate(
    across(
      .cols = c(starts_with("Participant"), -Participant.Age,
                Phase, starts_with("Condition"), -Condition.Test.Audio,
                starts_with("Item"), starts_with("Talker"),
                Response, Task, Exclude_Participant.Reason),
      .fns = factor),
    across(
      .cols = c(Participant.Age, Condition.Test.Audio, Response.RT, starts_with("Duration")),
      .fns = as.numeric),
    across(
      .cols = c(Item.isCatchTrial, Response.CatchTrial),
      .fns = as.logical)) %>%
  # Get rid of old cues (not clear whether those were imported correctly)
  select(!starts_with("cue")) %>%
  # Remove experiments with occluder manipulations (we won't need them)
  filter(!Experiment.internalName %in% c("NORM D", "NORM E"))

d.test <- 
  d.perception %>%
  filter(Phase == "test") %>%
  left_join(
    d.acoustics %>%
      filter(type == "test") %>%
      # Test items in acoustic data were identified based on the order of 31 steps in Liu & Jaeger (2018), 
      # but here we use the opposite order.
      mutate(word = 32 - as.numeric(word)) %>%
      select(cog, word, type),
    by = join_by(Phase == type, Condition.Test.Audio == word))

# We will be using only Experiments 1a-c from Cummings et al (2025) to estimate the effects of compenstation
d.test %<>%
  filter(Experiment.internalName %in% c("NORM A", "NORM B", "NORM C")) %>%
  run_exclusions(c("CISP-1a", "CISP-1b", "CISP-1c")) %>%
  excludeData() %>%
  filter(!is.na(Response.ASHI)) %>%
  ungroup() %>%
  # scaling cog to keep effect of priors same as for other predictors
  mutate(cog_gs = (cog - mean(cog)) / (2 * sd(cog)))
```

# Basics 


## Center of gravity by segment type
Using the stimuli from all experiments, the center of gravity (CoG) is higher for typical "s" than for typical "sh", with shifted "s" and "sh" falling into the middle of the CoG continuum. Test items, too, fall approximately in the middle of the CoG continuum. 

```{r}
d.acoustics %>%
  mutate(segment = factor(segment, levels = c("S", "SH", "?"))) %>%
  ggplot(aes(x = cog,
             fill = segment)) +
  geom_histogram(bins = 20, position = "identity", alpha = .5) +
  scale_x_continuous("center of gravity") +
  facet_wrap(~type)
```

## Effects of pen in test-only experiment
Replotting the effect of the pen along center of gravity (CoG), instead of continuum steps.

```{r}
d.test %>%
  ggplot(aes(x = cog,
             y = Response.ASHI,
             linetype = Condition.Test.Pen)) +
  stat_summary(geom = "pointrange",
               fun.data = mean_cl_boot) +
  stat_summary(geom = "line",
               fun = mean, aes(linetype = Condition.Test.Pen)) +
  scale_x_continuous("center of gravity") +
  scale_y_continuous("Proportion of ASHI-responses")
```

# Estimating effects of compensation

## Approach 1 [MORE CONTEXT NEEDED HERE]
We fit the same Bayesian mixed-effects logistic regression as in Cummings et al. (2025), except that we used the CoG instead of the continuum steps as a predictor.

```{r}
stats.cog <-
  d.test %>%
  summarise(mean = mean(cog), sd = sd(cog))

# Not sure that it makes any difference to include Experiment here 
# (but we're currently assuming as much below)
m1 <-
  brm(
    formula =
      Response.ASHI ~ 1 + Experiment * Condition.Test.Pen * Condition.Test.OriginalLabel * cog_gs +
      # Including experiment since there's clear evidence that the
      # selection of test steps affects how participants interpret the input
      # (presumable incl. cog).
      (1 + Condition.Test.Pen * Condition.Test.OriginalLabel * cog_gs | ParticipantID),
    data =
      d.test %>%
      prep_for_analysis(),
    family = "bernoulli",
    prior = my_priors,
    sample_prior = "yes",
    backend = "cmdstanr",
    chains = 4,
    warmup = 2000,
    iter = 4000,
    thin = 2,
    control = list(adapt_delta = .95, max_treedepth = 15),
    cores = min(parallel::detectCores(), 4),
    threads = threading(threads = 2),
    file = "../models/Exp-CISP-1a-c-acoustics")

summary(m1)
```

consider sampling instead such that the chance of being interpreted as /s/ vs /sh/ changes across continuum, rather than a strict cutoff

```{r}
# Cutoff values are the minimum probability that the segment must
# have to still be perceived as intended. Lower values thus imply
# stronger word superiority effects (less evidence is needed to
# still be willing to accept the segment as intended).
cutoff_s <- cutoff_sh <- 0.4


# create sample exposure data to test
# we want to check each exposure item with and without PIM
# (which should leave cog unaffected but will change the prediction)
#
# NOTE: THIS APPROACH MODELS THE PREDICTED EFFECT OF THE PEN ON THE PROBABILITY OF
# PERCEIVING A SEGMENT AS INTENDED. HOWEVER, IT MIGHT BE BETTER TO INSTEAD MODEL THE
# EFFECT ON THE PERCEIVED COG?
d.exp <-
  d.acoustics %>%
  filter(type != "test") %>%
  # Adding information about the visual bias, which---for exposure items---was always
  # the same as the intended category (i.e., segment)
  rename(Condition.Test.OriginalLabel = segment) %>%
  # scale cog based on statistics used for fitted model
  mutate(cog_gs = (cog - stats.cog$mean) / (2 * stats.cog$sd)) %>%
  crossing(
    Condition.Test.Pen = c("H", "M"),
    # Create one version of the data frame for each experiment
    # (since we included experiment in the model fit, we need
    # to include it in the newdata, and average over it below)
    Experiment = c("CISP-1a", "CISP-1b", "CISP-1c")) %>%
  # Get predictions ignoring random effects
  bind_cols(predict(m1, newdata = ., re_formula = NA)) %>%
  rename(Condition.Pen = Condition.Test.Pen, Condition.OriginalLabel = Condition.Test.OriginalLabel) %>%
  # average prediction across experiments (since we can't really
  # model the effects of selected continuum steps for the exposure
  # data anyway)
  group_by(word, type, Condition.OriginalLabel, Condition.Pen, cog, cog_gs) %>%
  summarise(predicted_probability.SH = mean(Estimate)) %>%
  # Define cutoff probabilities and determine whether segment would be
  # perceived as intended.
  mutate(
    cutoff_s = .env$cutoff_s,
    cutoff_sh = .env$cutoff_sh,
    Condition.Exposure =
      case_when(
        Condition.OriginalLabel == "S" & type == "typical" ~ "SH-bias",
        Condition.OriginalLabel == "S" & type == "shifted" ~ "S-bias",
        Condition.OriginalLabel == "SH" & type == "typical" ~ "S-bias",
        Condition.OriginalLabel == "SH" & type == "shifted" ~ "SH-bias"),
    segment.perceived_as_intended =
      case_when(
        Condition.OriginalLabel == "S" & 1 - predicted_probability.SH < .data$cutoff_s ~ "no",
        Condition.OriginalLabel == "S" & 1 - predicted_probability.SH >= .data$cutoff_s ~ "yes",
        Condition.OriginalLabel == "SH" & predicted_probability.SH < .data$cutoff_sh ~ "no",
        Condition.OriginalLabel == "SH" & predicted_probability.SH >= .data$cutoff_sh ~ "yes"))
```

## Approach 2: compensating before adaptation
We are estimating the *compensated* CoG for each exposure item. One way of doing so would be to invert the mixed-effects logistic regression model. But for now, we are calculating the prediction for the posterior probability of "sh" along a fine-stepped CoG continuum, while crossing the position of the pen (in mouth or hand) with the visual labeling information of the stimulus ("s" or "sh"). For each CoG step with a pen, we then find the CoG step without a pen that results in the most similar predicted posterior probability of "sh" while holding the visual labeling information identical.

```{r}
if (!RESET_MODELS & !file.exists("../data/sample_data_compensated.RData")) {
  sampledata <- 
    crossing(
      Condition.Test.OriginalLabel = c("S", "SH"),
      Condition.Test.Pen = c("H", "M"),
      Experiment = c("CISP-1a", "CISP-1b", "CISP-1c"),
      # Span the CoG continuum at .25 Hz steps, but also include all cog values that occur
      # in the actual data since we need those below
      cog = 
        c(
          d.acoustics$cog,
          seq(min(d.acoustics$cog), max(d.acoustics$cog), .25))) %>%
    # Convert into standardized CoG
    mutate(cog_gs = (cog - stats.cog$mean) / (2 * stats.cog$sd)) %>%
    # Get predictions ignoring random effects
    bind_cols(predict(m1, newdata = ., re_formula = NA, cores = 4)) %>%
    group_by(Condition.Test.OriginalLabel, Condition.Test.Pen, cog) %>%
    summarise(Estimate = mean(Estimate))
  
  # For each input with pen find the input without pen that has the most similar estimated 
  # posterior probability of "sh", while keeping the visual labeling information identical.
  sampledata_pen <- tibble()
  for (label in unique(sampledata$Condition.Test.OriginalLabel)) {
    temp_no_pen <-
      sampledata %>%
      filter(Condition.Test.Pen == "H", Condition.Test.OriginalLabel == label)
    
    temp_pen <-
      sampledata %>%
      filter(Condition.Test.Pen == "M", Condition.Test.OriginalLabel == label)
    
    temp_pen %<>%
      rowwise() %>% 
      mutate(
        closest_no_pen_estimate = temp_no_pen$Estimate[which.min(abs(Estimate - temp_no_pen$Estimate))], 
        closest_no_pen_cog = temp_no_pen$cog[which.min(abs(Estimate - temp_no_pen$Estimate))])
    
    sampledata_pen <- bind_rows(sampledata_pen, temp_pen)
  }

  save(sampledata_pen, file = "../data/sample_data_compensated.RData")
  rm(sampledata)
} else {
  load(file = "../data/sample_data_compensated.RData")
}
```

### Approximation error

```{r, fig.cap=c('Difference in posterior probability of "sh" between pen-in-mouth and pen-in-hand estimate in proportion space', 'Same but in log-odds')}
sampledata_pen %>%
  ggplot(aes(x = Estimate, y = Estimate - closest_no_pen_estimate)) +
  geom_line()

sampledata_pen %>%
  ggplot(aes(x = Estimate, y = qlogis(Estimate) - qlogis(closest_no_pen_estimate)))+
  geom_line()
```

```{r}
sampledata_pen %>%
  ggplot(aes(y = Estimate)) +
  geom_line(aes(x = cog), color = "black", alpha = .5) +
  geom_line(aes(x = closest_no_pen_cog), color = "red", alpha = .5) +
  facet_wrap(~ Condition.Test.OriginalLabel)

sampledata_pen %>%
  ggplot(aes(x = Estimate, y = closest_no_pen_cog - cog)) +
  geom_line() +
  facet_wrap(~ Condition.Test.OriginalLabel)
```

```{r}
d.exp.compensated <- 
  d.exp %>%
  left_join(
    sampledata_pen %>%
      select(Condition.Test.OriginalLabel, cog, closest_no_pen_cog),
    by = join_by(Condition.OriginalLabel == Condition.Test.OriginalLabel, cog == cog)) %>%
  mutate(
    cog_compensated = ifelse(Condition.Pen == "M", closest_no_pen_cog, cog),
    cog_gs_compensated = (cog_compensated - stats.cog$mean) / (2 * stats.cog$sd)) %>%
  rename(
    cog_gs_original = cog_gs,
    cog_gs = cog_gs_compensated,
    Condition.Test.Pen = Condition.Pen,
    Condition.Test.OriginalLabel = Condition.OriginalLabel) %>%
  crossing(Experiment = c("CISP-1a", "CISP-1b", "CISP-1c")) %>%
  # re-predict based on these new cogs
  bind_cols(predict(m1, newdata = ., re_formula = NA)) %>%
  rename(Condition.Pen = Condition.Test.Pen, Condition.OriginalLabel = Condition.Test.OriginalLabel) %>%
  # average prediction across experiments (since we can't really
  # model the effects of selected continuum steps for the exposure
  # data anyway)
  group_by(word, type, Condition.OriginalLabel, Condition.Pen, cog, cog_gs) %>%
  summarise(predicted_probability.SH = mean(Estimate)) %>%
  # Define cutoff probabilities and determine whether segment would be
  # perceived as intended.
  mutate(
    # Cutoff values are the minimum probability that the segment must
    # have to still be perceived as intended. Lower values thus imply
    # stronger word superiority effects (less evidence is needed to
    # still be willing to accept the segment as intended).
    cutoff_s = .env$cutoff_s,
    cutoff_sh = .env$cutoff_sh,
    Condition.Exposure =
      case_when(
        Condition.OriginalLabel == "S" & type == "typical" ~ "SH-bias",
        Condition.OriginalLabel == "S" & type == "shifted" ~ "S-bias",
        Condition.OriginalLabel == "SH" & type == "typical" ~ "S-bias",
        Condition.OriginalLabel == "SH" & type == "shifted" ~ "SH-bias"),
    segment.perceived_as_intended =
      case_when(
        Condition.OriginalLabel == "S" & 1 - predicted_probability.SH < cutoff_s ~ "no",
        Condition.OriginalLabel == "S" & 1 - predicted_probability.SH >= cutoff_s ~ "yes",
        Condition.OriginalLabel == "SH" & predicted_probability.SH < cutoff_sh ~ "no",
        Condition.OriginalLabel == "SH" & predicted_probability.SH >= cutoff_sh ~ "yes"))
```
## Comparison of approaches

```{r, fig.cap=c('Predicted probability of "sh" along CoG continuum for exposure items under Approach 1', "Same under Approach 2")}
d.exp %>%
  ggplot(
    aes(
      x = cog,
      y = predicted_probability.SH,
      color = Condition.Pen)) +
  scale_shape_manual(values = c(1, 19)) +
  geom_line(aes(linetype = type)) +
  facet_grid(Condition.Exposure ~ Condition.OriginalLabel)

d.exp.compensated %>%
  ggplot(
    aes(
      x = cog,
      y = predicted_probability.SH,
      color = Condition.Pen)) +
  scale_shape_manual(values = c(1, 19)) +
  geom_line(aes(linetype = type)) +
  facet_grid(Condition.Exposure ~ Condition.OriginalLabel)
```

```{r, fig.cap=c('Predicted consequences for lexical decisions during exposure under Approach 1', "Same under Approach 2")}
d.exp  %>%
  ggplot(aes(x = cog,
             y = predicted_probability.SH,
             color = segment.perceived_as_intended,
             shape = type)) +
  scale_shape_manual(values = c(1, 19)) +
  scale_color_manual(values = c("red", "green")) +
  geom_point() +
  facet_grid(Condition.Pen + Condition.Exposure ~ Condition.OriginalLabel)

d.exp.compensated  %>%
  ggplot(aes(x = cog,
             y = predicted_probability.SH,
             color = segment.perceived_as_intended,
             shape = type)) +
  scale_shape_manual(values = c(1, 19)) +
  scale_color_manual(values = c("red", "green")) +
  geom_point() +
  facet_grid(Condition.Pen + Condition.Exposure ~ Condition.OriginalLabel)
```

# Simulating effects of exposure

## Effects of exposure on distributional beliefs

### Pen in hand

```{r}
# make an IO based on the typical tokens (and no pen in mouth)
IO <-
  make_MVG_ideal_observer_from_data(
  data = d.exp %>% filter(Condition.Pen == "H", type == "typical"),
  category = "Condition.OriginalLabel",
  cues = "cog")

# and make an IA based on it
# and a random kappa and nu... could/should try others!
# pretty low for now just so effects are more visually evident
kappa_nu <- 20
IA <-
  IO %>%
  mutate(kappa = kappa_nu,
         nu = kappa_nu,
         prior_kappa = kappa_nu,
         prior_nu = kappa_nu,
         S = get_S_from_expected_Sigma(Sigma, nu)) %>%
  rename(m = mu) %>%
  select(!Sigma) %>%
  arrange(category)

# check classic exposure effect (pen in hand)
posterior_s_bias.PiH <-
  update_NIW_ideal_adaptor_incrementally(
    prior = IA,
    exposure =
      d.exp %>%
      # Make sure token that aren't perceived as intended are not used for updating
      mutate(cog = ifelse(segment.perceived_as_intended == "no", NA, cog)) %>%
      filter(
        Condition.Exposure == "S-bias",
        Condition.Pen == "H"),
    exposure.category = "Condition.OriginalLabel",
    exposure.cues = "cog")

posterior_sh_bias.PiH <-
  update_NIW_ideal_adaptor_incrementally(
    prior = IA,
    exposure =
      d.exp %>%
      # Make sure token that aren't perceived as intended are not used for updating
      mutate(cog = ifelse(segment.perceived_as_intended == "no", NA, cog)) %>%
      filter(
        Condition.Exposure == "SH-bias",
        Condition.Pen == "H"),
    exposure.category = "Condition.OriginalLabel",
    exposure.cues = "cog")

xlim <- c(4000, 8000)
plot_grid(
  p_priors <- plot_expected_categories_density_1D(filter(IA), xlim = xlim),
  p_sh_PiH <- plot_expected_categories_density_1D(filter(posterior_sh_bias.PiH, observation.n == max(observation.n)), xlim = xlim) + theme(legend.position = "none"),
  p_s_PiH <- plot_expected_categories_density_1D(filter(posterior_s_bias.PiH, observation.n == max(observation.n)), xlim = xlim) + theme(legend.position = "none"),
  labels = c("priors", "after SH-biased exposure (PiH)", "after S-biased exposure (PiH)"),
  hjust = 0,
  ncol = 1,
  align = "hv")
```

### Pen in mouth (without compensation)

```{r}
posterior_s_bias.PiM <-
  update_NIW_ideal_adaptor_incrementally(
    prior = IA,
    exposure =
      d.exp %>%
      # Make sure token that aren't perceived as intended are not used for updating
      mutate(cog = ifelse(segment.perceived_as_intended == "no", NA, cog)) %>%
      filter(
        Condition.Exposure == "S-bias",
        Condition.Pen == "M"),
    exposure.category = "Condition.OriginalLabel",
    exposure.cues = "cog")

posterior_sh_bias.PiM <-
  update_NIW_ideal_adaptor_incrementally(
    prior = IA,
    exposure =
      d.exp %>%
      # Make sure token that aren't perceived as intended are not used for updating
      mutate(cog = ifelse(segment.perceived_as_intended == "no", NA, cog)) %>%
      filter(
        Condition.Exposure == "SH-bias",
        Condition.Pen == "M"),
    exposure.category = "Condition.OriginalLabel",
    exposure.cues = "cog")

plot_grid(
  p_priors,
  p_sh_PiM <- plot_expected_categories_density_1D(filter(posterior_sh_bias.PiM, observation.n == max(observation.n)), xlim = xlim) + theme(legend.position = "none"),
  p_s_PiM <- plot_expected_categories_density_1D(filter(posterior_s_bias.PiM, observation.n == max(observation.n)), xlim = xlim) + theme(legend.position = "none"),
  labels = c("priors", "after SH-biased exposure (PiM)", "after S-biased exposure (PiM)"),
  hjust = 0,
  ncol = 1,
  align = "hv")

# Compare effect of SH-biased exposure for PiH vs. PiM
# plot_grid(p_priors, p_sh_PiH, p_sh_PiM,
#           ggplot(mapping = aes(color = category)) +
#             bind_rows(
#               filter(posterior_sh_bias.PiH, observation.n == max(observation.n)) %>%
#                 mutate(posterior = "PiH"),
#               filter(posterior_sh_bias.PiM, observation.n == max(observation.n)) %>%
#                 mutate(posterior = "PiM")) %>%
#             mutate(
#               mu = get_expected_mu_from_m(m),
#               Sigma = get_expected_Sigma_from_S(S, nu)) %>%
#             group_by(category, .add = T) %>%
#             group_map(.keep = T, .f = function(.x, .y)
#               stat_function(data = .x, mapping = aes(color = category),
#                             fun = function(x, mean1, sd1, mean2, sd2) dnorm(x, mean1, sd1) - dnorm(x, mean2, sd2),
#                             args = list(mean1 = .x$mu[[1]], sd1 = .x$Sigma[[1]]^0.5, mean2 = .x$mu[[2]], sd2 = .x$Sigma[[2]]^0.5))) +
#             scale_x_continuous(get_cue_labels_from_model(IA), limits = xlim, expand = c(0, 0)) +
#             scale_y_continuous("Density") +
#             theme(legend.position = "none"),
#           labels = c("prior", "after SH-biased exposure (PiH)", "after SH-biased exposure (PiM)", "difference between PiH - PiM"),
#           ncol = 1, hjust = 0, align = "hv")

summary <-
  rbind(
    mutate(IA,
           bias = "prior", pen = "H") %>%
      # Copy prior (for animation below)
      crossing(observation.n = 0:max(posterior_s_bias.PiH$observation.n)),
    mutate(posterior_s_bias.PiH,
           bias = "S", pen = "H"),
    mutate(posterior_sh_bias.PiH,
           bias = "SH", pen = "H"),
    mutate(posterior_s_bias.PiM,
           bias = "S", pen = "M"),
    mutate(posterior_sh_bias.PiM,
           bias = "SH", pen = "M"))
```
### Pen in mouth (with compensation)

```{r}
posterior_s_bias.PiM.compensated <-
  update_NIW_ideal_adaptor_incrementally(
    prior = IA,
    exposure =
      d.exp.compensated %>%
      # Make sure token that aren't perceived as intended are not used for updating
      mutate(cog = ifelse(segment.perceived_as_intended == "no", NA, cog)) %>%
      filter(
        Condition.Exposure == "S-bias",
        Condition.Pen == "M"),
    exposure.category = "Condition.OriginalLabel",
    exposure.cues = "cog")

posterior_sh_bias.PiM.compensated <-
  update_NIW_ideal_adaptor_incrementally(
    prior = IA,
    exposure =
      d.exp.compensated %>%
      # Make sure token that aren't perceived as intended are not used for updating
      mutate(cog = ifelse(segment.perceived_as_intended == "no", NA, cog)) %>%
      filter(
        Condition.Exposure == "SH-bias",
        Condition.Pen == "M"),
    exposure.category = "Condition.OriginalLabel",
    exposure.cues = "cog")

plot_grid(
  p_priors,
  p_sh_PiM.compensated <- plot_expected_categories_density_1D(filter(posterior_sh_bias.PiM, observation.n == max(observation.n)), xlim = xlim) + theme(legend.position = "none"),
  p_s_PiM.compensated <- plot_expected_categories_density_1D(filter(posterior_s_bias.PiM, observation.n == max(observation.n)), xlim = xlim) + theme(legend.position = "none"),
  labels = c("priors", "after SH-biased exposure (PiM)", "after S-biased exposure (PiM)"),
  hjust = 0,
  ncol = 1,
  align = "hv")

# Compare effect of SH-biased exposure for PiH vs. PiM
# plot_grid(
#   p_priors, p_sh_PiH, p_sh_PiM.compensated,
#   ggplot(mapping = aes(color = category)) +
#     bind_rows(
#       filter(posterior_sh_bias.PiH, observation.n == max(observation.n)) %>%
#         mutate(posterior = "PiH"),
#       filter(posterior_sh_bias.PiM, observation.n == max(observation.n)) %>%
#         mutate(posterior = "PiM")) %>%
#     mutate(
#       mu = get_expected_mu_from_m(m),
#       Sigma = get_expected_Sigma_from_S(S, nu)) %>%
#     group_by(category, .add = T) %>%
#     group_map(.keep = T, .f = function(.x, .y)
#       stat_function(data = .x, mapping = aes(color = category),
#                     fun = function(x, mean1, sd1, mean2, sd2) dnorm(x, mean1, sd1) - dnorm(x, mean2, sd2),
#                     args = list(mean1 = .x$mu[[1]], sd1 = .x$Sigma[[1]]^0.5, mean2 = .x$mu[[2]], sd2 = .x$Sigma[[2]]^0.5))) +
#     scale_x_continuous(get_cue_labels_from_model(IA), limits = xlim, expand = c(0, 0)) +
#     scale_y_continuous("Density") +
#     theme(legend.position = "none"),
#   labels = c("prior", "after SH-biased exposure (PiH)", "after SH-biased exposure (PiM)", "difference between PiH - PiM"),
#   ncol = 1, hjust = 0, align = "hv")

summary <-
  rbind(
    mutate(IA,
           compensated = "NA", bias = "prior", pen = "NA") %>%
      crossing(observation.n = 1:40),
    mutate(posterior_s_bias.PiM,
           compensated = "no", bias = "S", pen = "M"),
    mutate(posterior_sh_bias.PiM,
           compensated = "no", bias = "SH", pen = "M"),
    mutate(posterior_s_bias.PiH,
           compensated = "no", bias = "S", pen = "H"),
    mutate(posterior_sh_bias.PiH,
           compensated = "no", bias = "SH", pen = "H"),
    mutate(posterior_s_bias.PiM.compensated,
           compensated = "yes", bias = "S", pen = "M"),
    mutate(posterior_sh_bias.PiM.compensated,
           compensated = "yes", bias = "SH", pen = "M"))
```

## Effects on expected categorization function

```{r, fig.width=5}
p <- 
  plot_expected_categorization_function_1D(
    summary %>% 
      group_by(compensated, bias, pen) %>% 
      mutate(
        pen = ifelse(bias == "prior", "H", pen),
        pen = ifelse(compensated == "yes", "M (compensated)", pen)) %>%
      filter(observation.n == max(observation.n)),
    data.test = d.test,
    xlim = xlim,
    target_category = 2) +
  aes(color = bias,
      linetype = pen) +
  scale_color_manual(values = c("black", "red", "blue")) +
  scale_linetype(labels = c("H", "M", "M (compensated)")) +
  theme(legend.position = "right")

p
```

```{r, fig.show="animate"}
a <- 
  animate(
    plot_expected_categorization_function_1D(
      summary %>% 
        group_by(compensated, bias, pen, observation.n) %>% 
        mutate(
          pen = ifelse(bias == "prior", "H", pen),
          pen = ifelse(compensated == "yes", "M (compensated)", pen)),
      data.test = d.test,
      xlim = xlim,
      target_category = 2) +
      aes(color = bias,
          linetype = pen) +
      scale_color_manual(values = c("black", "red", "blue")) +
      scale_linetype(labels = c("H", "M", "M (compensated)")) +
      theme(legend.position = "right") +
      transition_states(observation.n, transition_length = 2, state_length = 1), 
    width = 500, height = 500, 
  fps = 5, renderer = av_renderer())

a
anim_save("../figures/updating.webm", a)
```
# Finding optimal fit

next steps:
 -import the exposure-test data 

   - fit behavior to predictions
   - free params (before belief updating!):
   - lapse rate, noise, priors themselves

 - additional free params for learning:
   -  kappa/nu, cutoff endorsement rate, whether low-CoG /s/ is considered /sh/. 

 - belief updater can infer the prior given enough data
   - infer_NIW_ideal_adaptor()
   - but probably better to fit based on 1c data (without pen)

Some other notes
  - optim calcs liklihood of s/sh cat given cog (MAX this not min)
  - winter and Xie stimulus order accomodation to space

## Using likelihood maximization

```{r}
predict_for_optim = function(CoG, model_predict, pars) {
  # prediction function from priors
  cat_func <- priors_ALL %>%
    mutate(m = c(pars[1], pars[2]),
           S = c(pars[3], pars[4])) %>%
    get_categorization_function_from_NIW_ideal_adaptor()
  
  diff = abs(model_predict - (1 - cat_func(CoG)))
  
  # prediction function from model
  return(sum(diff))
}

d.control.model.foroptim <- 
  d.control.test.formodel %>%
  group_by(Talker, CoG, CoG_gs) %>%
  slice(1) %>%
  mutate(Cycle.s = 0) %>%
  bind_cols(estimate = predict(control.model, newdata = ., re.form = NA)) %>%
  mutate(p.ASI = plogis(estimate)) %>%
  group_by(Talker) %>%
  nest() %>%
  mutate(optim =
           map2(
             .x = data,
             .y = Talker,
             .f = ~ optim(
               par = c(
                 priors_ALL %>% filter(category == "SH") %>% pull(m) %>% as.numeric(),
                 priors_ALL %>% filter(category == "SS") %>% pull(m) %>% as.numeric(),
                 priors_ALL %>% filter(category == "SH") %>% pull(S) %>% as.numeric(),
                 priors_ALL %>% filter(category == "SS") %>% pull(S) %>% as.numeric()),
               method = "L-BFGS-B",
               lower = c(1000, 6000, 10000000, 10000000),
               upper = c(8000, 12000, 100000000, 100000000),
               fn = predict_for_optim,
               CoG = .x$CoG,
               model_predict = .x$p.ASI,
               control = list(maxit = 1000,
                              parscale = c(10, 10, 1000, 1000))))) %>%
  unnest(cols = "optim") %>%
  separate(col = optim, 
           into = c("mean_sh", "mean_s", "S_sh", "S_s"), sep = ", ") %>%
  filter(!is.na(S_sh)) %>%
  mutate(mean_sh = str_sub(mean_sh, 3, nchar(mean_sh) - 2),
         S_s = str_sub(S_s, 1, nchar(S_s) - 1))
```